# Khmer Medical Q&A Dataset - Clean Structure

## ğŸ“‚ Directory Structure (Post-Cleanup)

```
khmer-medic-nano/
â”œâ”€â”€ README.md                    # Project overview
â”œâ”€â”€ DATASET_SUMMARY.md          # Dataset statistics
â”œâ”€â”€ CLAUDE.md                   # AI assistant instructions
â”œâ”€â”€ Makefile                    # Build automation
â”œâ”€â”€ .env.example                # Environment template
â”œâ”€â”€ upload_success.json         # HF upload confirmation
â”‚
â”œâ”€â”€ configs/                    # Configuration files
â”‚   â”œâ”€â”€ project.yaml           # Project settings
â”‚   â”œâ”€â”€ prompt_translate.txt  # Translation prompts
â”‚   â”œâ”€â”€ prompt_paraphrase.txt # Paraphrase prompts
â”‚   â””â”€â”€ prompt_summary.txt    # Summary prompts
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ out/                   # Final outputs
â”‚   â”‚   â”œâ”€â”€ km_final.jsonl            # Complete dataset (90.4 MB)
â”‚   â”‚   â”œâ”€â”€ km_complete_augmented.jsonl # Fully augmented (55 MB)
â”‚   â”‚   â””â”€â”€ validation_report.json    # Quality metrics
â”‚   â”‚
â”‚   â””â”€â”€ training_formats/      # Ready-to-use formats (334 MB)
â”‚       â”œâ”€â”€ alpaca_train.jsonl
â”‚       â”œâ”€â”€ alpaca_val.jsonl
â”‚       â”œâ”€â”€ chatml_train.jsonl
â”‚       â”œâ”€â”€ chatml_val.jsonl
â”‚       â”œâ”€â”€ llama_train.txt
â”‚       â”œâ”€â”€ llama_val.txt
â”‚       â”œâ”€â”€ qwen_train.txt
â”‚       â”œâ”€â”€ qwen_val.txt
â”‚       â”œâ”€â”€ supervised_train.jsonl
â”‚       â”œâ”€â”€ supervised_val.jsonl
â”‚       â”œâ”€â”€ training_config.json
â”‚       â””â”€â”€ README.md
â”‚
â”œâ”€â”€ huggingface_dataset/       # HF package (201 MB)
â”‚   â”œâ”€â”€ README.md              # Dataset card
â”‚   â”œâ”€â”€ dataset_info.json     # Metadata
â”‚   â”œâ”€â”€ data/                  # Parquet files
â”‚   â”œâ”€â”€ complete_augmented/   # Augmented subset
â”‚   â””â”€â”€ jsonl/                 # JSONL versions
â”‚
â”œâ”€â”€ scripts/                   # Essential scripts only
â”‚   â”œâ”€â”€ create_training_formats.py
â”‚   â”œâ”€â”€ upload_to_hf.py
â”‚   â”œâ”€â”€ validate_dataset_fixed.py
â”‚   â””â”€â”€ check_hf_user.py
â”‚
â””â”€â”€ archive_backup/            # Archived processing files
    â””â”€â”€ [timestamped folders]
```

## ğŸ¯ Quick Start

### Use the Dataset
```python
from datasets import load_dataset

# From HuggingFace Hub
dataset = load_dataset('khopilot/khmer-medical-qa')

# From local files
import json
with open('data/out/km_final.jsonl', 'r') as f:
    data = [json.loads(line) for line in f]
```

### Train a Model
```bash
# Use pre-formatted training data
python train.py --data data/training_formats/qwen_train.jsonl
```

### Validate Quality
```bash
python scripts/validate_dataset_fixed.py data/out/km_final.jsonl
```

## ğŸ“Š Dataset Info
- **Total entries**: 18,756 medical Q&A pairs
- **With paraphrases**: 9,314 (49.7%)
- **With reasoning**: 18,753 (100%)
- **Quality score**: 94.6/100
- **HuggingFace**: https://huggingface.co/datasets/khopilot/khmer-medical-qa

## ğŸ—‚ï¸ Archived Files
Processing artifacts and intermediate files have been moved to `archive_backup/` 
to keep the main directory clean while preserving them for reference.
